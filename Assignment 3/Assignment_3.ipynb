{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e31133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5adeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "imdb = load_dataset(\"imdb\")\n",
    "print(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade1ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device            : cuda\n",
      "==========================================================================================\n",
      "Initial Memory left     : 4095.5 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device            :\", device)\n",
    "\n",
    "def left_cuda_memory():\n",
    "    reserved = torch.cuda.memory_reserved() / 1024**2    # in MB\n",
    "    total = torch.cuda.get_device_properties(0).total_memory / 1024**2  # in MB\n",
    "    free = total - reserved\n",
    "    print(\"=\"*90)\n",
    "    return free\n",
    "print(f\"Initial Memory left     : {left_cuda_memory()} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "919830bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81f2e669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token length | 50, 75, 80, 90, 95 : [232.   376.   429.   602.   785.05]\n",
      "Choosen max lentgh: 512\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Subset the dataset\n",
    "small_train = imdb[\"train\"].select(range(15000))\n",
    "small_test = imdb[\"test\"].select(range(10000))\n",
    "\n",
    "\n",
    "train_texts = small_train[\"text\"]\n",
    "token_lengths = [len(tokenizer.tokenize(text)) for text in train_texts]\n",
    "print(f\"token length | 50, 75, 80, 90, 95 : {np.percentile(token_lengths, [50, 75, 80, 90, 95])}\")\n",
    "max_len = int(np.percentile(token_lengths, 90))\n",
    "\n",
    "if max_len>512:\n",
    "    max_len=512\n",
    "    print(f\"Choosen max lentgh: {max_len}\")\n",
    "else: \n",
    "    print(f'90th percentile choosen: {max_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a97b5b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Tokenization function using dynamic max_length\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_len\n",
    "    )\n",
    "\n",
    "# Step 3: Tokenize datasets\n",
    "tokenized_dataset = {\n",
    "    \"train\": small_train.map(tokenize_function, batched=True),\n",
    "    \"test\": small_test.map(tokenize_function, batched=True)\n",
    "}\n",
    "\n",
    "# Set format for PyTorch\n",
    "for split in [\"train\", \"test\"]:\n",
    "    tokenized_dataset[split].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# Step 4: DataLoader creation\n",
    "train_loader = DataLoader(tokenized_dataset[\"train\"], batch_size=8, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(tokenized_dataset[\"test\"], batch_size=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa9feedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimating per epoch training time and GPU memory left...\n",
      "==========================================================================================\n",
      "GPU Memory left             : 809.50 MB\n",
      "Estimated time per epoch    : 44.11 minutes\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW \n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Optimizer and criterion\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "def run_batches(model, loader, device, steps=None, show_progress=False):\n",
    "    model.train()\n",
    "    loop = tqdm(enumerate(loader), total=steps or len(loader), disable=not show_progress)\n",
    "    start_time = time.time()\n",
    "\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    for step, (idx, batch) in enumerate(loop):\n",
    "        if steps and step >= steps:\n",
    "            print(f\"GPU Memory left             : {left_cuda_memory():.2f} MB\")\n",
    "            break\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if show_progress:\n",
    "            loop.set_description(\"Training\")\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    return time.time() - start_time\n",
    "\n",
    "# Run warmup\n",
    "print(\"\\nEstimating per epoch training time and GPU memory left...\")\n",
    "warmup_time = run_batches(model, train_loader, device, steps=10)\n",
    "estimated_epoch_time = (warmup_time / 10) * len(train_loader)\n",
    "print(f\"Estimated time per epoch    : {estimated_epoch_time / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcec97f",
   "metadata": {},
   "source": [
    "Actual Model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa950ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for 1 epoch...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 256/1875 [08:40<56:58,  2.11s/it, loss=0.457]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "GPU Memory left: 2669.50 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 512/1875 [17:41<51:12,  2.25s/it, loss=0.384]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "GPU Memory left: 2669.50 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 768/1875 [25:57<38:06,  2.07s/it, loss=0.32] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "GPU Memory left: 2669.50 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1024/1875 [34:23<30:07,  2.12s/it, loss=0.28] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "GPU Memory left: 2669.50 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1280/1875 [55:34<22:19,  2.25s/it, loss=0.26]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "GPU Memory left: 2669.50 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1536/1875 [1:03:41<11:54,  2.11s/it, loss=0.241]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "GPU Memory left: 2669.50 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1792/1875 [1:11:13<02:41,  1.95s/it, loss=0.226]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "GPU Memory left: 2669.50 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [1:13:51<00:00,  2.36s/it, loss=0.224]\n",
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after epoch 1 saved to model_final.pt\n",
      "\n",
      "============================================================\n",
      "Epoch 1 Summary:\n",
      "  Avg Train Loss : 0.2240\n",
      "  Train Accuracy : 0.9135\n",
      "  Avg Test Loss  : 0.0568\n",
      "  Test Accuracy  : 0.9840\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# === CONFIG ===\n",
    "epochs = 1\n",
    "accumulation_steps = 4\n",
    "memory_check_step = 256\n",
    "lr = 2e-5\n",
    "weight_decay = 0.01\n",
    "\n",
    "# === OPTIMIZER, LOSS, SCALER ===\n",
    "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion = CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "# === SCHEDULER ===\n",
    "total_steps = len(train_loader) * epochs\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(\"\\nStarting training for 1 epoch...\\n\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ——— TRAINING ———\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    train_loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=True)\n",
    "    for step, batch in train_loop:\n",
    "        input_ids      = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels         = batch[\"label\"].to(device)\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss / accumulation_steps\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()  # <<< Step the scheduler here\n",
    "\n",
    "        running_loss += loss.item() * accumulation_steps\n",
    "        train_loop.set_postfix(loss=running_loss / (step + 1))\n",
    "\n",
    "        preds = outputs.logits.argmax(dim=1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_total   += labels.size(0)\n",
    "\n",
    "        if (step + 1) % memory_check_step == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"GPU Memory left: {left_cuda_memory():.2f} MB\")\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_acc      = train_correct / train_total\n",
    "\n",
    "    # ——— TESTING ———\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "            input_ids      = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels         = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            test_loss += outputs.loss.item()\n",
    "\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            test_correct += (preds == labels).sum().item()\n",
    "            test_total   += labels.size(0)\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_acc      = test_correct / test_total\n",
    "\n",
    "    # ——— SAVE MODEL ———\n",
    "    torch.save(model.state_dict(), \"model_final.pt\")\n",
    "    print(\"Model after epoch 1 saved to model_final.pt\")\n",
    "\n",
    "    # ——— EPOCH SUMMARY ———\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Epoch {epoch+1} Summary:\")\n",
    "    print(f\"  Avg Train Loss : {avg_train_loss:.4f}\")\n",
    "    print(f\"  Train Accuracy : {train_acc:.4f}\")\n",
    "    print(f\"  Avg Test Loss  : {avg_test_loss:.4f}\")\n",
    "    print(f\"  Test Accuracy  : {test_acc:.4f}\")\n",
    "    print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd1925",
   "metadata": {},
   "source": [
    "Reloading the model and for larger test set and plotting accuracy metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0b98c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.load_state_dict(torch.load(\"model_final.pt\"))\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60a4b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing unseen data for tesing (10k - 25k)\n",
    "\n",
    "total = len(imdb[\"test\"])  \n",
    "small_test = imdb[\"test\"].select(range(total - 15000, total))\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_len\n",
    "    )\n",
    "\n",
    "tokenized_test = small_test.map(tokenize_function, batched=True)\n",
    "tokenized_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "test_loader = DataLoader(tokenized_test, batch_size=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "281ed1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [20:04<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted F1 Score: 0.8159\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4428    0.9884    0.6116      2500\n",
      "           1     0.9969    0.7512    0.8568     12500\n",
      "\n",
      "    accuracy                         0.7907     15000\n",
      "   macro avg     0.7198    0.8698    0.7342     15000\n",
      "weighted avg     0.9046    0.7907    0.8159     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "#performing final evaluation\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = outputs.logits.argmax(dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "#Metrices\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')  \n",
    "print(f\"\\nWeighted F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
